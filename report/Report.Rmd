---
title: "tidyMC"
subtitle: "An easy-to-use package for Monte-Carlo Simulations"
type: "Report"
author: "Ignacio Moreira Lara, Stefan Linner, Konstantin Lehmann"
discipline: "M.Sc. Econometrics"
date: "`r Sys.Date()`"
supervisor: "Jens Klenke"
secondsupervisor: "Martin C. Arnold"
studid: 230658, 233565, 229994
cols_authors: 4
estdegree_emester: "Summer Term 2022"
deadline: "06.09.2022"
output:
  pdf_document:
    extra_dependencies: ["lmodern", "mathtools", "amsmath", "amsfonts", "soul"]
    keep_tex: yes
    template: template.tex
    fig_caption: yes
    citation_package: biblatex
    number_sections: false
toc: false
lot: false
lof: false
graphics: true
biblio-title: References
fontsize: 10pt
geometry: lmargin=2.5cm,rmargin=2.5cm,tmargin=2.5cm,bmargin=2.5cm
biblio-files: references_tidy.bib
classoption: a4paper
language: english
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# library(profvis)
# library(purrr)
# library(dplyr)
# library(tibble)
# library(rlang)
# library(ggplot2)
devtools::load_all()
```

# Introduction
Monte Carlo Simulations (henceforth MCS) are used to study the properties of econometrics inference techniques by simulation. 
They are almost always part of theoretical econometric research to study the performance of some inference technique. They supplement theoretical research most often in one of four ways. Firstly, they are often used to assess the performance of asymptotically valid techniques in smaller samples. Secondly, they are often used to assess how robust a technique is to violations of its theoretical assumptions. Thirdly, they allow to compare the performance of different techniques for a given data generating process (DGP). Fourthly, MCS allows to investigate the properties of inference techniques for which no analytical solution exists.  Moreover, MCS itself can  be used as a statistical inference technique itself. For example, Bootstrap Inference can be conceptualized as a special case of MCS. Beyond these examples, there are many more areas where MCS is used. However, independent of its use-case, easy and efficient implementation of MCS is currently only sparsely available.

With our tidyMC package, we want to enable researchers to easily and efficiently include MCS in their research using the programming language R. For one, tidyMC allows to easily speed up MCS by providing efficient parallelization options over a pre-specified parameter grid. Because MCS involves repeated computation, using parallel workers allows for significant computation time reductions. For another, tidyMC returns an easy to work with output. The output allows to access the result of all simulations for every parameter combination in the parameter grid. Moreover, tidyMC provides functions to effectively communicate the results of the MCS.  Using the output, the simulation results can then be easily visualized using the package's plot function. Because the function returns a ggplot object, researchers can customize the object to their liking. Additionally, the package provides a function that converts the results into publication-ready LaTex tables. The table is heavily customizable and thereby allows researchers to effectively communicate their results. 

This report is structured as follows. Section \@ref(monte-carlo-simulation) gives an introduction to why and how Monte Carlo 
simulations work and provides a simple OLS example. Section \@ref(package-principles) explains the coding practices we followed and gives a conceptual overview of how we implemented MCS in R. Section \@ref(vignette) presents tidyMC's vignette. The vignette gives an easy-to-follow guide on how to implement MCS using the tidyMC package. Section \@ref(comparison-to-other-monte-carlo-approaches-in-r) compares the performance of tidyMC to the performance of the MonteCarlo package and other potential MCS implementations.  Section \@ref(conclusion) concludes. 

# Monte Carlo Simulation {MCS}
MCS allow analyzing the properties of classic econometric inference techniques. As a simulation-based technique, MCS applies a statistical procedure to many synthetically created samples. The repeated application of the procedure to a fully known DGP helps to investigate properties of statistical techniques in two situations. For one, it allows to scrutinize the properties of asymptotically consistent estimators in smaller samples. For another, it helps to analyze properties in situations which are analytically not solvable. In this section we want to give a brief overview how and in which circumstances work, mainly following.
<!-- \citep{kiviet_monte_2011}. -->


## Pseudo Random Number Generation and the Data Generating Process
Using MCS on computers has the great advantage that, with the necessary information, the simulations results can be replicated everywhere. This is possible because, given seed and algorithm, the numbers created by a random number generator are completely reproducible. 
MCS generally starts with a synthetically created i.i.d. sample. Computers are, however, not able to generate truly random draws from different distributions. Instead the computer's draws from different distributions that are generated through pseudo-random draws from a uniform distribution. While we do not provide a detailed description of the different algorithms used, we explain the underlying intuition behind random number generation. 

Creating pseudo-random numbers from a probability distribution generally requires creating pseudo-random draws from a standard uniform distribution. Draws from a uniform distribution are created through the application of a certain algorithm, called random number generators (RNG), to a natural number, called the seed. The created values are pseudo-random because they are indistinguishable from truly random numbers but are fully determined by the combination of the algorithm and the seed. Combined knowledge of the algorithm and the seed allows exact replication of a series of pseudo-random numbers generated. The possibility to replicate the draws allows to exactly reproduce results that build on the pseudo-randomly generated number on different computers. 

The most common algorithm, as well as R's standard algorithm, used for the generation of pseudo-random draws from a standard uniform distribution, is the Mersenne-Twister algorithm. There are however more algorithms available. In R it is also possible to specify your own algorithm to create pseudo-random numbers.  The purpose of the tidyMC-package is to additionally allow easy parallelization od the MCS. With parallel computing, special attention has to be payed to create disjoint and sufficiently long sets of draws from a uniform distribution. Our package builds on R-standard Lâ€™Ecuyer-CMRG RNG streams. The algorithm creates reproducible sets of $U[0,1]$ numbers for each parallel worker, using an integer seed of length 7. Alternatively a seed of length 1 is accepted, which corresponds to a valid seed of length 7. Because the algorithm creates a subset of random numbers for each workers, the stream and hence the MCS results are only reproducible if the same number of parallel workers is used. Alternatively our function allows to supply user-generated lists of random variables. 

Generating pseudo-random numbers from more complex distributions uses the distribution's cumulative distribution function (CDF). It can be shown that every random variable $X$ has a CDF $F$ if $X = F^{-1}(U)$, where U is a random variable uniformly distributed on $(0,1)$. Pseudo-random draws from different probability distributions are conceptually implemented by applying the inverse of CDF to pseudo-random numbers from the uniform distribution. Direct application of the inverse CDF is however often computationally time-consuming and requires that the inverse CDF is analytically available. To account for the two shortcomings different approaches have been developed for specific distributions, that also easily extend to random vectors. While they build on the idea to use the inverse of the CDF, their concrete design is out of the scope of this paper. A general overview can be found in the documentation of the respective R-functions. 

Complex multivariate distribution can then be simulated as functions of standard distributions. A typical example of that is a linear conditional expectation functions, the work horse model of econometrics. In the following example, we will showcase how MCS allows to simulate the correct distribution of the coefficients.

## Monte Carlo Distrbution Approximation
MCS is most commonly used to infer properties of the distribution of statistic in a fixed settting, i.e. for a prespecified DGP. The simulation results hence hold only for the prespecified DGP. Because it additionally only approximates the distribution numerically, we need to control for the resulting approximation inaccuracies.  

In MCs we generally simulate the distribution of a statistic $q_n$. The statistic can often be expressed as a function of a parameter vector $\beta$, some deterministic variables $D$ and some random variables $v$, s.t. $q_n = q_n(\theta,D,v,n)$. What a Monte Carlos simulation ultimately achieves is a numerical approximation of the true distribution of $q_n$. In a simple i.id. setting an application of the CLT. Let $q_n^R$ be the statistic generate by the $R^th$ Monte Carlo Simulation. What we get is that as the histogram of all $q_n^R$ becomes a unbiased and consistent estimator of $q_n$. ADD THE FORMAL STUFF HERE. p.36! And add here discontciotn between histogram and 
We are hence able to control the precision of the approximation by setting the number of Monte Carlo estimates. Using the resulting distribution $q_n^R$ we can then use different statistics such as mean and variance to summarize the result. 


### Presenting MCS findngs
p. 122 add maybe here?

<!-- For example we might be interested in the ability of OLS to estimate the variable parameter $\beta_1$ of a simple linear regression model with deterministic regressor. -->
<!-- In that case specify the model $y_i = \beta_0 + \beta_1 x_i + \epsilon_i$ with corresponding true population paramterers $\theta  = (\beta_0, \beta_1)$, $D = X$ a $n \times 2$ matrix of the deterministic x and the intercept $\beta_0$, and $c = \epsilon$ a $n \times 1$ of $\mathcal{N}(0, \sigma_\epsilon)$ as a normally distributed error term. Using OLS, we estimate $\hat{\beta_1}$ as the second element of $(X^TX)^{-1}X^Ty$. With OLS then $\hat{\beta}_1(\theta, D, v)$. In a MCS we would then generate r $\hat{\beta_1}$ to study how well OLS is able to capture the true $\beta_1$.  -->
<!-- Show distribution of interval  -->

# Monte Carlo example

## OLS consistency

To demonstrate how a MCS works, we provide an example using the estimation of a linear model using the ordinary least squares(OLS) estimator. Given a dependent variable $y$ and a set of i.id. regressors $X = \{x_1, x_2\}$ we consider the linear DGP 
\begin{equation}
	\label{eq_DGP}
	y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \varepsilon,
\end{equation}  
where $\beta  = \{\beta_0, \beta_1, \beta_2\}$ are the coefficients and $\varepsilon$ is a normally distributed error term with variance $\sigma^2$, i.e. $\varepsilon \sim \mathcal{N}(0,\sigma^2)$. The corresponding OLS estimators $\hat{beta}$ and $s^2$ for $\beta$ and $\sigma^2$  are
\begin{align}
	\hat{\beta} = (XX)^{-1} XY,\\
	s^2 =   \frac{1}{n-k} \hat{\varepsilon}' \hat{\varepsilon},
\end{align}
where $k = 2$ is the number of regressors and $\hat{\varepsilon}$ is the vector of residuals. Both estimators are consistent and unbiased. Accordingly OLS should be able to correctly estimate the coefficients for every sample size, while the precision of the estimates should increase in the sample size. 

<!-- Maybe add also estimator of the variance here. We know the theoretical variance of the coefficients and we can then add that to the plot: nice demonstration of how to amend the outputted ggplot object. -->

\noindent Using a MCS we can demonstrate the properties of the OLS estimator. Fixing the coefficients $\beta = \{1, 4, 5\}$ and $\sigma^2 = 3$, we generate different DGPs by using different normal distributions to generate the dependent variables  $x_1$ and $x_2$. Additionally, we generate $\varepsilon$ from its respective distribution. 

Now the parameter of interest for our function is the number of observations we use for our estimation, for this we set $n = \{100, 200, 300\}$. 
<!-- Paramter of interest in whch sense -->

Lastly, we repeat this process 10000 times for each parameter combination. 
<!-- Paramter of interest in whch sense -->

We present the results in table \ref{tab:ols_table}, where the first column is related to the number of observations we use in the estimation. The last 4 columns show the results' mean over a preset number of the 10000 repetitions for each parameter combination. In the first panel the mean over the estimated coefficients from only the 10 first repetitions is calculated; the subsequent panel shows the mean calculated using all Monte Carlo repetitions. 
<!-- What dies that mean -->
The results demonstrate the performance of OLS estimation with increasing sample sizes. As expected figureh \l{(XX)} and table \hl{(XX)}  confirm that a bigger sample size leads to a more precise estimation of the underlying population values. Comparing both panels, we see that this behavior is just confirmed, as the estimated values do not differ and they become more precise.
<!-- Table should include se of the coefficients -->

```{r, echo = FALSE, eval = TRUE, results = "hide", message=FALSE, fig.show='hide'}
ols_test <-
  function(b0, b1, b2, n, sigma2, param_x1, param_x2, inc_x2){

    # generation of data
    x1 <- rnorm(n = n, mean = param_x1[1], sd = param_x1[2])
    x2 <- rnorm(n = n,  mean = param_x2[1], sd = param_x2[2])
    e <- rnorm(n, sd = sqrt(sigma2))
    y <- b0 + b1*x1 + b2*x2 + e

    if (inc_x2 == 0){
      x2 <- x2 * inc_x2
    }

    # application of method
    estim <- lm(y ~ x1 + x2)

    # evaluation of the result for a single repetition and parameter combination
    out <- list(B0 = estim$coefficients[1],
                B1 = estim$coefficients[2],
                B2 = estim$coefficients[3],
                s2 = var(estim$residuals))
    return(out)
  }


param_list_ols <-
  list(n = c(100, 200, 300))

ols <- future_mc(fun = ols_test, repetitions = 10000, param_list = param_list_ols,
                 b0 = 1, b1 = 4, b2 = 5, param_x1 = c(1,2), param_x2 = c(3,4),
                 sigma2 = 3, inc_x2 = 1)
ols_plots <- plot(ols, plot = FALSE)
```

```{r ols_table, echo = FALSE}

tidy_mc_latex(summary(ols), repetitions_set = c(10, 10000),
                           column_names = c("Number of observations",
                                            "$\\beta_0$", "$\\beta_1$",
                                            "$\\beta_2$", "$s^2$"),
              caption = "OLS consistency MC results") %>%
  kableExtra::kable_styling(latex_options = "HOLD_position")

```
Similarly to show the convergence of the estimators in a graphical manner, we present histograms of the estimated coefficients for all values of $n$. We present the histograms for $\hat{\beta_1}$ and $s^2$ in figures \ref{fig:ols_b1} and \hl{(XX)}, and include the remaining plots in the Appendix. 
<!-- we hsoe denities and not histograms, which are two different things.-->
The pattern for both figures is clear, the increase in $n$ reduces the variance of the estimator around the true value, thus the consistency of OLS is empirically visible.
<!-- Consistent is the wrong term here..-->

```{r ols_b1, echo = FALSE, fig.cap="MC $\\beta_1$ results"}
ols_plots$B1

```

```{r ols_s2, echo = FALSE, fig.cap="MC $s^2$ results"}
ols_plots$s2

```



##Ommited variable bias and irrelevant regressor inclusion

Moreover, another common problem for estimation is the inclusion of suitable regressors into the model. Both the inclusion irrelevant variables and the absence of relevant ones relevant ones into the regression model cause problems when estimating the true parameters. In this section, we will test the impact both of these problems on the estimated values.
\noindent We continue with the same structure as in equation \eqref{eq_DGP}, however we will test the case when $\beta_2 = 0$ which means that $x_2$ has no influence over $y$. This causes a problem in the estimation when the researcher does not know the underlying DGP and includes $x_2$ to the model, because of lack of information or convenience. \textit{A priori} the expected result is that the estimated coefficient associated with this new variable will be 0, while the variance of the residuals however will increase.

\noindent We test this hypothesis using a Monte Carlo study, where we use the same coefficient values as for the base example, except that we set $\beta_2=0$. Then we run an OLS model with $x_1$ and $x_2$ as the regressors using $n = (100, 200, 300)$. Lastly, we repeat this 10000 times for every value of $n$. We present the obtained results in table \ref{eq:irr_ols_table}. Two panels are presented again, one for the mean results of the ten first MC repetitions and the second for all repetitions. Again the hypothesis about the behavior of the coefficients is proven to be right, i.e. the estimators for $\beta_0$ and $\beta_1$ appear to converge to the true value. In contrast, the estimator for $\beta_2$ is marginally different from zero for all values of $n$, and from the overall mean results we conclude that this behavior does not change. Lastly, the last point of the hypothesis about the estimator of the variance of the error term is also proven to be right. This is because the results for the estimator $s^2$ have higher values compared to the ones obtained in table \ref{ols_table}. 

```{r, echo = FALSE, eval = TRUE, results = "hide", message=FALSE}
ols_irr <- future_mc(fun = ols_test, repetitions = 10000,
                     param_list = param_list_ols, b0 = 1, b1 = 4,
                     b2 = 0, param_x1 = c(1,2), param_x2 = c(3,4),
                     sigma2 = 3, inc_x2 = 1)

```


```{r irr_ols_table, echo = FALSE}
tidy_mc_latex(summary(ols_irr), repetitions_set = c(10, 10000),
                               column_names = c("Number of observations",
                                            "$\\beta_0$", "$\\beta_1$",
                                                "$\\beta_2$", "$s^2$"),
              caption = "MC OLS results with an irrelevant variable") %>%
  kableExtra::kable_styling(latex_options = "HOLD_position")

```

Lastly, we test the effects of estimating a model using only $x_1$ when the underlying DGP follows the structure of \eqref{eq_DGP}, this problem is most commonly known as having an omitted variable bias. The theoretical consequences of this problem are related to the consistency and unbiasedness of the estimators. Since it is necessary that $x_1$ and $x_2$ share a degree of correlation between them, the absence of one of them in the regression model will cause the available variable to be correlated with the error term, thus violating one of the main assumptions of this methodology. This correlation will lead to an estimator of $\beta_1$ to have a higher or lower expected value (depending on the sign of the correlation) in comparison to the true parameter.

# Package Principles {MCS}


# Vignette{vignette}


```{r , echo = FALSE , eval = TRUE, results = "hide", message=FALSE}
param_list_ols <- param_list_ols <-
  list(n = c(100, 200, 300), inc_x2 = c(0,1))

ols_omi <- future_mc(fun = ols_test, repetitions = 10000,
                     param_list = param_list_ols, b0 = 1, b1 = 4,
                     b2 = 5, param_x1 = c(1,2), param_x2 = c(3,4),
                     sigma2 = 3)


```
Operationally, we test this theoretical behavior using the same structure as for the last examples, now however we do not include $x_2$ into our estimated model. We present the results in table \ref{tab:ommiols}. To see a clearer difference we present the results for both models where $x_2$ is included and where is not. We see a clear difference in the estimated coefficients, on one hand the estimated intercept is completely overestimated, averaging around a value of 16 no matter the number of observations used or the number of MC replications. On the other hand, the estimated variance of the error term is also completely overestimated and does not seem to converge to the real value. We conclude that the absence of one important variable in the model has a bigger impact when compared to the inclusion of an irrelevant variable.

```{r ommiols, echo = FALSE}
tidy_mc_latex(summary(ols_omi), repetitions_set = c(10, 10000),
                           column_names = c("Number of observations",
                                            "$x_2$ included or not",
                                            "$\\beta_0$", "$\\beta_1$",
                                            "$\\beta_2$", "$s^2$"),
              caption = "Ommited variable bias MC results") %>%
  kableExtra::kable_styling(latex_options = "HOLD_position")

```







# Comparison to other Monte Carlo Approaches in R{comparsion}


# Conclusion
With the tidyMC package we provide research an easy and confortable way to to Monte Carlo Studies. 


# Strucutre
-Introduction to MCS (5)
- How it works in our package (10)
  - parallelisation plan
  - function
  - return objects
    - objects
    - summary
    - plots
    - tables 
  - exampl of outputs
  - extension: bootstrap
- Comparison to Monte Carlos package (3)
  - objects
  - speed
    -bench::mark
- Vignette

\end{document}

